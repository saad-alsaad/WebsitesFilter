##Websites Filter
The Project aim to build a classification model to detect if a website is safe or not.<br> 
The work is done using Python libraries like Pandas/Numpy/Sklearn/Seaborn/Matplotlib.<br>
####Follow the EDA steps.<br>
- Cleaning and removing unneeded values and features.
- Check if we have missing values in our data and fix them.
- Calculate basic summaries for our data, mean, maximum, minimum, mode, Standard Deviation, and q1/q2/q3 values for each feature.
- Do normalization if needed. 
- Find the correlation between the features by generating a heatmap and correlation matrix.
- Remove unneeded features (like the features that are highly correlated and have low correlation with the target feature)
- Generate box plots for the most correlated features and related to my target feature to spot the outliers easily. 
- Visualize the relation between the most correlated features with the target features using bivariate analysis. 

####Try 4 machine learning algorithms that may work properly with our dataset:
- KNN
- Logistic Regression
- SVM
- Random Forest

The final step will be choosing the better algorithm by comparing the performance and learning curve between the models.