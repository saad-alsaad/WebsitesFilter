<h2>Websites Filter</h2>
The Project aim to build a classification model to detect if a website is safe or not.<br> 
The work is done using Python libraries like Pandas/Numpy/Sklearn/Seaborn/Matplotlib.<br>
<h4>Follow the EDA steps.</h4>
<ul>
<li>Cleaning and removing unneeded values and features.</li>
<li>Check if we have missing values in our data and fix them.</li>
<li>Calculate basic summaries for our data, mean, maximum, minimum, mode, Standard Deviation, and q1/q2/q3 values for each feature.</li>
<li>Do normalization if needed.</li>
<li>Find the correlation between the features by generating a heatmap and correlation matrix.</li>
<li>Remove unneeded features (like the features that are highly correlated and have low correlation with the target feature).</li>
<li>Generate box plots for the most correlated features and related to my target feature to spot the outliers easily.</li>
<li>Visualize the relation between the most correlated features with the target features using bivariate analysis.</li>
</ul>
<h4>Try 4 machine learning algorithms that may work properly with our dataset:</h4>
<ul>
<li>KNN</li>
<li>Logistic Regression</li>
<li>SVM</li>
<li>Random Forest</li>
</ul>
<br>
The final step will be choosing the better algorithm by comparing the performance and learning curve between the models.
